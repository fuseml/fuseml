---
apiVersion: triggers.tekton.dev/v1alpha1
kind: TriggerTemplate
metadata:
  name: mlflow-triggertemplate
  namespace: fuseml-workloads
spec:
  params:
    - name: gitrevision
      description: The git revision
      default: main
    - name: gitrepositoryurl
      description: The git repository url
    - name: namespace
      description: The namespace to create the resources
    - name: appname
      description: Name of the app to stage/run
  resourcetemplates:
    - apiVersion: tekton.dev/v1beta1
      kind: PipelineRun
      metadata:
        generateName: fuseml-mlflow-$(tt.params.appname)-
        labels:
          fuseml/app-name: $(tt.params.appname)
      spec:
        serviceAccountName: staging-triggers-admin
        serviceAccountNames:
          - taskName: train
            serviceAccountName: fuseml-workloads
        pipelineRef:
          name: mlflow-pipeline
        workspaces:
          - name: source
            volumeClaimTemplate:
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 2Gi
        params:
          - name: image
            value: registry.fuseml-registry/apps/$(tt.params.appname)
          - name: appname
            value: $(tt.params.appname)
        resources:
          - name: source-repo
            resourceSpec:
              type: git
              params:
                - name: revision
                  value: $(tt.params.gitrevision)
                - name: url
                  value: $(tt.params.gitrepositoryurl)

---
apiVersion: triggers.tekton.dev/v1alpha1
kind: TriggerBinding
metadata:
  name: mlflow-pipelinebinding
  namespace: fuseml-workloads
spec:
  params:
    - name: gitrevision
      value: $(body.head_commit.id)
    - name: namespace
      value: fuseml-workloads
    - name: gitrepositoryurl
      value: "http://gitea-http.gitea:10080/$(body.repository.full_name)"
    - name: appname
      value: "$(body.repository.name)"

---
apiVersion: triggers.tekton.dev/v1alpha1
kind: EventListener
metadata:
  name: mlflow-listener
  namespace: fuseml-workloads
spec:
  serviceAccountName: staging-triggers-admin
  triggers:
    - bindings:
        - ref: mlflow-pipelinebinding
      template:
        ref: mlflow-triggertemplate

---
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: mlflow-pipeline
  namespace: fuseml-workloads
spec:
  workspaces:
    - name: source
  params:
    - name: image
    - name: appname
  resources:
    - name: source-repo
      type: git
  tasks:
    - name: clone
      taskRef:
        name: clone
      resources:
        inputs:
          - name: source-repo
            resource: source-repo
      workspaces:
        - name: source
          workspace: source
    - name: get-serving-type
      taskRef:
        name: get-serving-workload
      runAfter:
        - clone
      workspaces:
        - name: source
          workspace: source
    - name: build
      taskRef:
        name: kaniko
      runAfter:
        - clone
      params:
        - name: BUILDER_IMAGE
          value: "gcr.io/kaniko-project/executor:v1.5.1"
        - name: IMAGE
          value: $(params.image)
        - NAME: DOCKERFILE
          value: "app/.fuseml/Dockerfile"
        - name: CONTEXT
          value: app
        - name: EXTRA_ARGS
          value: "--skip-tls-verify"
      workspaces:
        - name: source
          workspace: source
    - name: train
      taskRef:
        name: train
      runAfter:
        - build
      params:
        - name: IMAGE
          value: "127.0.0.1:30500/apps/$(params.appname)@$(tasks.build.results.IMAGE-DIGEST)"
        - name: EXPERIMENT_NAME
          value: $(params.appname)
      workspaces:
        - name: source
          workspace: source
    - name: prepare-trained-model
      when:
        - input: "$(tasks.get-serving-type.results.type)"
          operator: in
          values: ["kfserving", "seldon_sklearn"]
      taskRef:
        name: model-pkl-to-joblib
      runAfter:
        - train
      params:
        - name: model-uri
          value: $(tasks.train.results.MODEL-URI)
    - name: serve
      taskRef:
        name: serve
      runAfter:
        - train
      params:
        - name: IMAGE-SHA
          value: $(tasks.build.results.IMAGE-DIGEST)
        - name: MODEL-URI
          value: $(tasks.train.results.MODEL-URI)
        - name: SERVING-TYPE
          value: $(tasks.get-serving-type.results.type)
      workspaces:
        - name: source
          workspace: source

---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: clone
  namespace: fuseml-workloads
spec:
  workspaces:
    - name: source
  resources:
    inputs:
      - name: source-repo
        type: git
        targetPath: source/app
  steps:
    - name: stage
      image: lachlanevenson/k8s-kubectl
      workingDir: "/workspace/source/app"
      script: |
        pwd
        ls -la

---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: train
  namespace: fuseml-workloads
spec:
  params:
    - name: IMAGE
      description: Name (reference) of the image to run
    - name: EXPERIMENT_NAME
      description: Name of experiment
  workspaces:
    - name: source
  results:
    - name: MODEL-URI
      description: location where the trained model is stored.
  steps:
    - name: run
      image: $(params.IMAGE)
      workingDir: "/workspace/source/app"
      script: |
        mlflow run --no-conda --experiment-name $(params.EXPERIMENT_NAME) . 2>&1 | tee train.log
      env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow"
        - name: MLFLOW_S3_ENDPOINT_URL
          value: "http://mlflow-minio:9000"
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: mlflow-minio
              key: accesskey
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: mlflow-minio
              key: secretkey
    - name: model-uri-to-results
      image: $(params.IMAGE)
      workingDir: "/workspace/source/app"
      script: |
        run_id=$(grep -oEm1 '[a-f0-9]{32}' train.log)
        model_uri="$(mlflow runs describe --run-id ${run_id} | grep -oEm1 's3.*artifacts')/model"
        printf "${model_uri}" | tee $(results.MODEL-URI.path)
      env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow"
        - name: MLFLOW_S3_ENDPOINT_URL
          value: "http://mlflow-minio:9000"
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: mlflow-minio
              key: accesskey
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: mlflow-minio
              key: secretkey

---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: serve
  namespace: fuseml-workloads
spec:
  params:
    - name: IMAGE-SHA
    - name: MODEL-URI
    - name: SERVING-TYPE
  workspaces:
    - name: source
  steps:
    - name: run
      image: lachlanevenson/k8s-kubectl
      workingDir: "/workspace/source/app"
      script: |
        #!/bin/sh
        case "$(params.SERVING-TYPE)" in
          "seldon_mlflow"|"seldon_sklearn"|"kfserving"|"seldon_tensorflow")
            sed "s#__MODEL_URI__#$(params.MODEL-URI)#g; s#__AWS_ACCESS_KEY_ID__#${AWS_ACCESS_KEY_ID}#g; s#__AWS_SECRET_ACCESS_KEY__#${AWS_SECRET_ACCESS_KEY}#g" .fuseml/serve.yaml | kubectl apply -f -
            #TODO: when kfserving installation is part of this tool, remove replacing AWS credentials and instead create a service account for kfserving as part of its installation
          ;;
          "deployment"|"knative")
            sed "s#__MODEL_URI__#$(params.MODEL-URI)#g; s#__IMAGE_SHA__#$(params.IMAGE-SHA)#g;" .fuseml/serve.yaml | kubectl apply -f -
          ;;
        esac
      env:
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: mlflow-minio
              key: accesskey
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: mlflow-minio
              key: secretkey

---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: get-serving-workload
  namespace: fuseml-workloads
spec:
  workspaces:
    - name: source
  results:
    - name: type
      description: indicates which workload will be used to deploy the model
  steps:
    - name: get-serving-workload
      workingDir: "/workspace/source/app"
      image: alpine
      script: |
        awk '/fuseml\/serving/ { gsub(/"/, "", $2); printf $2 }' .fuseml/serve.yaml | tee $(results.type.path)

---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: model-pkl-to-joblib
  namespace: fuseml-workloads
spec:
  params:
    - name: model-uri
  steps:
    - name: pkl-to-joblib
      image: minio/mc
      script: |
        #!/bin/sh
        model_s3uri=$(params.model-uri)
        mc alias set minio http://mlflow-minio:9000 ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY}
        mc cp minio${model_s3uri//s3:\//}/model.pkl minio${model_s3uri//s3:\//}/model.joblib
      env:
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: mlflow-minio
              key: accesskey
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: mlflow-minio
              key: secretkey
